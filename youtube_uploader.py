import os
import pandas as pd
import requests
from tqdm import tqdm
import pickle
import urllib.parse
import logging
import time

from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

CSV_FILE = "videos.csv"
DOWNLOAD_FOLDER = "downloads"
LOG_FILE = "upload_log.log"
SCOPES = ["https://www.googleapis.com/auth/youtube.upload"]
BASE_STORAGE_URL = "https://storage101.lon3.clouddrive.com/v1/MossoCloudFS_359702fa-5130-4cf4-9e74-778f0ddc61ed/ateretMordecay"
BASE_WEBSITE_URL = "https://www.ateretmordechai.org/%D7%90%D7%A8%D7%9B%D7%99%D7%95%D7%9F-%D7%A9%D7%99%D7%A2%D7%95%D7%A8%D7%99%D7%9D?view=media&id="

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def authenticate_youtube():
    logger.info("ğŸ” ××××ª ××ª YouTube API...")
    creds = None

    if os.path.exists("token.pickle"):
        with open("token.pickle", "rb") as token:
            creds = pickle.load(token)
        logger.info("âœ… ×˜×•×§×Ÿ × ××¦× ×•× ×˜×¢×Ÿ")
        logger.info("ğŸ’¡ ×× ××ª×” ×¨×•×¦×” ×œ×”×ª×—×‘×¨ ×œ×¤×¨×•×™×§×˜ ×—×“×©, ××—×§ ××ª ×§×•×‘×¥ token.pickle")

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            logger.info("ğŸ”„ ××¨×¢× ×Ÿ ×˜×•×§×Ÿ...")
            creds.refresh(Request())
        else:
            logger.info("ğŸŒ ××‘×§×© ×”×¨×©××•×ª ×—×“×©×•×ª...")
            try:
                flow = InstalledAppFlow.from_client_secrets_file(
                    "credentials.json", SCOPES
                )
                creds = flow.run_local_server(port=0)
            except Exception as e:
                if "access_denied" in str(e) or "403" in str(e):
                    logger.error("âŒ ×©×’×™××ª 403: access_denied")
                    logger.error("=" * 60)
                    logger.error("×”××¤×œ×™×§×¦×™×” ×‘××¦×‘ Testing. ×›×“×™ ×œ×¤×ª×•×¨:")
                    logger.error("1. ×”×™×›× ×¡ ×œ-Google Cloud Console")
                    logger.error("2. ×œ×š ×œ-APIs & Services > OAuth consent screen")
                    logger.error("3. ×”×•×¡×£ ××ª ×¢×¦××š ×œ-Test users")
                    logger.error("4. ××—×§ ××ª token.pickle ×•×”×¤×¢×œ ××—×“×©")
                    logger.error("=" * 60)
                raise
        with open("token.pickle", "wb") as token:
            pickle.dump(creds, token)
        logger.info("âœ… ××™××•×ª ×”×•×©×œ× ×‘×”×¦×œ×—×”")

    return build("youtube", "v3", credentials=creds)


def download_file(url, out_path, max_retries=3):
    logger.info(f"â¬‡ï¸ ××ª×—×™×œ ×”×•×¨×“×”: {url}")
    logger.info(f"ğŸ“ ×™×¢×“: {out_path}")
    
    for attempt in range(max_retries):
        try:
            r = requests.get(url, stream=True, timeout=30)
            r.raise_for_status()
            total_size = int(r.headers.get('content-length', 0))

            with open(out_path, 'wb') as f, tqdm(
                desc=os.path.basename(out_path),
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024
            ) as bar:
                for chunk in r.iter_content(chunk_size=1024*1024):
                    if chunk:
                        f.write(chunk)
                        bar.update(len(chunk))

            logger.info(f"âœ… ×”×•×¨×“×” ×”×•×©×œ××”: {out_path}")
            return True
        except requests.exceptions.RequestException as e:
            logger.warning(f"âš ï¸ × ×›×©×œ × ×™×¡×™×•×Ÿ ×”×•×¨×“×” {attempt + 1}/{max_retries}: {str(e)}")
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 5
                logger.info(f"â³ ×××ª×™×Ÿ {wait_time} ×©× ×™×•×ª ×œ×¤× ×™ × ×™×¡×™×•×Ÿ ×—×•×–×¨...")
                time.sleep(wait_time)
            else:
                logger.error(f"âŒ ×”×”×•×¨×“×” × ×›×©×œ×” ×œ××—×¨ {max_retries} × ×™×¡×™×•× ×•×ª")
                raise


def resumable_upload(youtube, file_path, title, description, tags, max_retries=5):
    logger.info(f"ğŸ“¤ ××ª×—×™×œ ×”×¢×œ××” ×œ×™×•×˜×™×•×‘: {title}")
    
    body = {
        "snippet": {
            "title": title,
            "description": description,
            "tags": tags.split(",") if tags else []
        },
        "status": {
            "privacyStatus": "public"
        }
    }

    media = MediaFileUpload(file_path, chunksize=1024*1024*8, resumable=True)
    request = youtube.videos().insert(
        part="snippet,status",
        body=body,
        media_body=media
    )

    file_size = os.path.getsize(file_path)
    uploaded = 0
    
    with tqdm(total=file_size, unit="B", unit_scale=True, desc="â¬†ï¸ Uploading", initial=0) as bar:
        response = None
        retry_count = 0
        
        while response is None and retry_count < max_retries:
            try:
                error = None
                while response is None:
                    try:
                        status, response = request.next_chunk()
                        if status:
                            uploaded = status.resumable_progress
                            bar.update(status.resumable_progress - bar.n)
                    except HttpError as e:
                        error = e
                        if e.resp.status in [500, 502, 503, 504]:
                            # Server error - retry
                            logger.warning(f"âš ï¸ ×©×’×™××ª ×©×¨×ª: {e.resp.status}. ×× ×¡×” ×œ×”××©×™×š...")
                            time.sleep(2 ** retry_count)  # Exponential backoff
                            break
                        else:
                            raise
                
                if response is not None:
                    logger.info(f"âœ… ×”×•×¢×œ×” ×‘×”×¦×œ×—×”! Video ID: {response['id']}")
                    logger.info(f"ğŸ”— https://www.youtube.com/watch?v={response['id']}")
                    break
                    
            except HttpError as e:
                retry_count += 1
                if retry_count >= max_retries:
                    logger.error(f"âŒ ×”×”×¢×œ××” × ×›×©×œ×” ×œ××—×¨ {max_retries} × ×™×¡×™×•× ×•×ª: {str(e)}")
                    raise
                else:
                    wait_time = min(2 ** retry_count, 60)  # Max 60 seconds
                    logger.warning(f"âš ï¸ ×©×’×™××” ×‘×”×¢×œ××” (× ×™×¡×™×•×Ÿ {retry_count}/{max_retries}): {str(e)}")
                    logger.info(f"â³ ×××ª×™×Ÿ {wait_time} ×©× ×™×•×ª ×œ×¤× ×™ × ×™×¡×™×•×Ÿ ×—×•×–×¨...")
                    time.sleep(wait_time)
                    
            except Exception as e:
                retry_count += 1
                if retry_count >= max_retries:
                    logger.error(f"âŒ ×©×’×™××” ×œ× ×¦×¤×•×™×”: {str(e)}")
                    raise
                else:
                    wait_time = min(2 ** retry_count, 60)
                    logger.warning(f"âš ï¸ ×©×’×™××” (× ×™×¡×™×•×Ÿ {retry_count}/{max_retries}): {str(e)}")
                    logger.info(f"â³ ×××ª×™×Ÿ {wait_time} ×©× ×™×•×ª ×œ×¤× ×™ × ×™×¡×™×•×Ÿ ×—×•×–×¨...")
                    time.sleep(wait_time)

    return response


def main():
    logger.info("=" * 60)
    logger.info("ğŸš€ ××ª×—×™×œ ×ª×”×œ×™×š ×”×¢×œ××” ×œ×™×•×˜×™×•×‘")
    logger.info("=" * 60)
    
    try:
        youtube = authenticate_youtube()
        df = pd.read_csv(CSV_FILE)
        
        # Ensure 'uploaded' column exists and fill NaN values with empty string
        if "uploaded" not in df.columns:
            df["uploaded"] = ""
        df["uploaded"] = df["uploaded"].fillna("").astype(str)
        
        logger.info(f"ğŸ“Š × ××¦××• {len(df)} ×©×•×¨×•×ª ×‘×§×•×‘×¥ CSV")
        
        uploaded_count = len(df[df["uploaded"].str.lower() == "yes"])
        remaining_count = len(df) - uploaded_count
        logger.info(f"âœ… ×›×‘×¨ ×”×•×¢×œ×•: {uploaded_count} | ğŸ“¤ × ×•×ª×¨×•: {remaining_count}")

        os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

        for idx, row in df.iterrows():
            # Skip if already uploaded
            if str(row.get("uploaded", "")).lower() == "yes":
                title_text = str(row.get("title", "N/A")).strip()
                logger.info(f"â­ï¸ ×“×™×œ×•×’ ×¢×œ ×©×•×¨×” {idx + 1}: ×›×‘×¨ ×”×•×¢×œ×” - {title_text}")
                continue

            # Build title: rabi + cat + title
            rabi = str(row.get("rabi", "")).strip()
            cat = str(row.get("cat", "")).strip()
            title = str(row.get("title", "")).strip()
            video_title = f"{rabi} - {cat} - {title}" if rabi and cat else (f"{cat} - {title}" if cat else title)
            
            logger.info(f"\n{'=' * 60}")
            logger.info(f"ğŸ“¹ ××¢×‘×“ ×©×•×¨×” {idx + 1}/{len(df)}: {video_title}")
            logger.info(f"{'=' * 60}")

            # Build full URL
            url_path = str(row.get("url", "")).strip()
            if not url_path.startswith("http"):
                # Add base URL if not already a full URL
                if url_path.startswith("/"):
                    full_url = BASE_STORAGE_URL + url_path
                else:
                    full_url = BASE_STORAGE_URL + "/" + url_path
            else:
                full_url = url_path
            
            logger.info(f"ğŸ”— URL ××œ×: {full_url}")
            
            parsed = urllib.parse.urlparse(full_url)
            file_name = os.path.basename(parsed.path)  # filename only without ?params
            # Remove query parameters from filename
            if "?" in file_name:
                file_name = file_name.split("?")[0]
            local_file = os.path.join(DOWNLOAD_FOLDER, file_name)

            # Check if file already exists
            if os.path.exists(local_file):
                file_size = os.path.getsize(local_file)
                logger.info(f"âœ… ×§×•×‘×¥ ×›×‘×¨ ×§×™×™×: {local_file} ({file_size / (1024*1024):.2f} MB)")
                logger.info("â­ï¸ ×“×™×œ×•×’ ×¢×œ ×”×•×¨×“×”, ×××©×™×š ×œ×”×¢×œ××”...")
            else:
                # Download file
                try:
                    download_file(full_url, local_file)
                except Exception as e:
                    logger.error(f"âŒ ×©×’×™××” ×‘×”×•×¨×“×”: {str(e)}")
                    logger.error(f"â­ï¸ ×“×™×œ×•×’ ×¢×œ ×©×•×¨×” {idx + 1}")
                    continue

            # Build description
            csv_id = str(row.get("id", "")).strip()
            added_date = str(row.get("added", "")).strip()
            
            # Remove " 0:00" from date if exists
            if added_date and " 0:00" in added_date:
                added_date = added_date.replace(" 0:00", "")
            
            website_link = BASE_WEBSITE_URL + csv_id if csv_id else ""
            
            description = "×“×¤×™ ××§×•×¨×•×ª ×•×§×•×‘×¥ ×©××¢ ×‘×¢××•×“ ×”×©×™×¢×•×¨ ×‘××ª×¨ ×”×™×©×™×‘×”"
            if website_link:
                # Create clickable HTML link
                description += f"\n\n<a href=\"{website_link}\">{website_link}</a>"
            if added_date:
                description += f"\n\n×ª××¨×™×š: {added_date}"

            # Upload to YouTube
            try:
                response = resumable_upload(
                    youtube,
                    local_file,
                    video_title,
                    description,
                    ""  # No tags field in new CSV format
                )
                
                if response:
                    youtube_video_id = response.get("id") if isinstance(response, dict) else None
                    if youtube_video_id:
                        youtube_url = f"https://youtu.be/{youtube_video_id}"
                        df.at[idx, "youtube_url"] = youtube_url
                        logger.info(f"ğŸ”— × ×©××¨ ×§×™×©×•×¨: {youtube_url}")
                    df.at[idx, "uploaded"] = "yes"
                    df.to_csv(CSV_FILE, index=False)
                    logger.info("ğŸ“Œ ×¡×•××Ÿ ×›-uploaded âœ… ×•× ×©××¨ ×œ×§×•×‘×¥ CSV")
                    
                    # Delete file after successful upload
                    try:
                        if os.path.exists(local_file):
                            file_size = os.path.getsize(local_file)
                            os.remove(local_file)
                            logger.info(f"ğŸ—‘ï¸ ×§×•×‘×¥ × ××—×§: {local_file} ({file_size / (1024*1024):.2f} MB)")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ××—×•×§ ××ª ×”×§×•×‘×¥ {local_file}: {str(e)}")
                else:
                    logger.error("âŒ ×”×”×¢×œ××” × ×›×©×œ×”")
                    
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×”×¢×œ××”: {str(e)}")
                logger.error(f"â­ï¸ ×××©×™×š ×œ×©×•×¨×” ×”×‘××”...")
                continue

        logger.info(f"\n{'=' * 60}")
        logger.info("ğŸ‰ ×›×œ ×”×”×¢×œ××•×ª ×”×¡×ª×™×™××•!")
        logger.info(f"{'=' * 60}")
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×§×¨×™×˜×™×ª: {str(e)}")
        raise


if __name__ == "__main__":
    main()
